{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmerDiaaeldin/testrepo/blob/main/NNFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vzUDhkkddAi"
      },
      "source": [
        "## Building a neural network from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2vweLucd76j"
      },
      "source": [
        "Trying to build the neural network using OOP <br>\n",
        "I'll define a layer class, then use it to define a neural network class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Cq62HIloD3dX"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "RX2oIwkh4AmJ"
      },
      "outputs": [],
      "source": [
        "# Define a layer class, now this is a base class for generally any NN layer. All\n",
        "# layers have input, output, forward_prop, backward_prop. Now depending on the NN\n",
        "# one.\n",
        "# one can use this base class to add features specific to the application they have in\n",
        "# mind (Pooling, convolution, activation,...etc) \n",
        "\n",
        "class Layer:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "\n",
        "  #returns the output of the layer given the input\n",
        "  def forward_propagation(self, input):\n",
        "    return NotImplementedError\n",
        "\n",
        "  #returns the dE/dX for a given dY/dX (and update parameters)\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    return NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "ka6cBFftdIud"
      },
      "outputs": [],
      "source": [
        "class FCLayer(Layer):\n",
        "\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.W = np.random.rand(output_size, input_size) - 0.5 #initialize W, the parameter matrix\n",
        "    self.b = np.random.rand(output_size, 1) - 0.5 #initialize b, the bias\n",
        "\n",
        "  #for the forward propagation I'm going to feed it W and the input, and return from it the output of the layer\n",
        "  def forward_propagation(self, input):\n",
        "    #print(f\"W's shape : {self.W.shape}\")\n",
        "    #print(f\"X's shape : {input.shape}\")\n",
        "    #print(f\"b's shape : {self.b.shape}\")\n",
        "    self.input = input  #assign the layer input when forward propagating\n",
        "    self.output = np.matmul(self.W, self.input) + self.b\n",
        "    #print(self.output[0])\n",
        "    return self.output\n",
        "\n",
        "  #computes dE/dW and dE/db for a given output_error = dE/dY, updates W and b, and finally returns dE/dX\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    input_error = np.matmul(np.transpose(self.W),output_error)\n",
        "    W_error = np.matmul(output_error, np.transpose(self.input))\n",
        "    #b_error = output_error\n",
        "    #print(f\"output's error : {output_error.shape}\")\n",
        "    #print(f\"b's error : {b_error.shape}\")\n",
        "\n",
        "    #update the parameters\n",
        "    self.W -= learning_rate * W_error\n",
        "    self.b -= learning_rate * np.sum(output_error,axis=1,keepdims=True)\n",
        "\n",
        "    return input_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yi4um6QtNRP"
      },
      "source": [
        "Now let's code some non-linear layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Wzamg7LftM7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ActivationLayer(Layer):\n",
        "\n",
        "  def __init__(self, activation, activation_derivative):\n",
        "    super().__init__()\n",
        "    self.activation = activation\n",
        "    self.activation_derivative = activation_derivative\n",
        "\n",
        "  def forward_propagation(self, input):\n",
        "    self.input = input\n",
        "    self.output = self.activation(self.input)\n",
        "    return self.output\n",
        "\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    return self.activation_derivative(self.input)*output_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6ZQgUtjN4N7"
      },
      "source": [
        "tanh and relu activations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ljdkkz3_th-L"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "  return (1-np.tanh(x)**2)\n",
        "\n",
        "def relu(x):\n",
        "  return max(0,x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "  return (x>0)*1\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  s = sigmoid(x)\n",
        "  return s*(1-s)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbiEtmM3N8Tm"
      },
      "source": [
        "Time to code losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "zjvcdlumN-uY"
      },
      "outputs": [],
      "source": [
        "def mse(y_true, y_pred):\n",
        "  return np.mean(np.power(y_true-y_pred,2))\n",
        "\n",
        "def mse_derivative(y_true, y_pred):\n",
        "  return 2*(y_pred-y_true)/y_true.size\n",
        "\n",
        "def entropy(y_true, y_pred):\n",
        "  #print(\"y_pred min = \", np.min(y_pred))\n",
        "  lg1 = np.log(y_pred)\n",
        "  print(\"lg1 min\",np.min(lg1))\n",
        "  z1 = -1*np.multiply(y_true,lg1)\n",
        "  lg0 = np.log(1-y_pred)\n",
        "  print(\"lg0 min\",np.min(lg0))\n",
        "  z0 = -1*np.multiply(1-y_true,lg0)\n",
        "  z = np.mean(z0 + z1)\n",
        "  return np.mean(z)\n",
        "\n",
        "def entropy_derivative(y_true, y_pred):\n",
        "  result = -y_true*1/y_pred + (1-y_true)/(1-y_pred)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "\n",
        "  z = np.argmax(y_pred, axis = 0)\n",
        "  prediction = np.zeros(y_pred.shape)\n",
        "  for element in enumerate(z):\n",
        "    prediction[tuple(reversed(element))] = 1\n",
        "\n",
        "  return 100*(1 - (np.sum(np.abs(y_true-prediction))//2)/prediction.size)"
      ],
      "metadata": {
        "id": "X_irGFIeoyVN"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5heE3fKwv3cI"
      },
      "source": [
        "# Finally the network class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "HsC9gOEdv3HN"
      },
      "outputs": [],
      "source": [
        "class Network:  #it is basically a list of layer objects\n",
        "  def __init__(self):\n",
        "    self.loss = None\n",
        "    self.layers = []\n",
        "    self.loss_derivative = None\n",
        "\n",
        "  #adds a layer object to the network\n",
        "  def add(self, layer):\n",
        "    self.layers.append(layer)\n",
        "\n",
        "  #set the loss function of the network\n",
        "  def use(self, loss, loss_derivative):\n",
        "    self.loss = loss\n",
        "    self.loss_derivative = loss_derivative\n",
        "\n",
        "  #make predictions\n",
        "  def predict(self,input_data):\n",
        "    # the input data must be a rank-2 tensor (matrix) (# of examples x # of features)\n",
        "    output = input_data\n",
        "    #print(output.shape)\n",
        "    i = 1\n",
        "    for layer in self.layers:\n",
        "      #print(i)\n",
        "      i += 1\n",
        "      output = layer.forward_propagation(output)\n",
        "      #print(output.shape)\n",
        "    return output\n",
        "\n",
        "  #fit the network\n",
        "  def fit(self, X_train, y_train, epochs, learning_rate):\n",
        "    for epoch in range(epochs):\n",
        "      y_pred = self.predict(X_train)\n",
        "      #print(\"y_pred min : \", np.min(y_pred))\n",
        "      #print(\"y_pred max : \", np.max(y_pred))\n",
        "      err = self.loss(y_train, y_pred)\n",
        "      #print(\"losses = \", err)\n",
        "      error = self.loss_derivative(y_train, y_pred)\n",
        "      #print(\"minimum derivative = \", np.min(error))\n",
        "      #print(\"maximum derivative = \", np.max(error))\n",
        "      for layer in self.layers[-1::-1]:\n",
        "        error = layer.backward_propagation(error, learning_rate)\n",
        "\n",
        "      err = np.mean(err)\n",
        "      print(f\"epoch {epoch+1}/{epochs} error = {err}\")\n",
        "      print(\"test accuracy : \",accuracy(y_train, y_pred),end=\"\\n\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYH1kz8o6Iw5"
      },
      "source": [
        "Testing time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjcWbupzcqSj"
      },
      "source": [
        "Trying the mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "EFYaMZX47_8h"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "data = mnist.load_data()\n",
        "(x_train,y_train), (x_test, y_test) = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLiclG3fd-jo",
        "outputId": "8b75a827-a378-44da-a422-295a3b5a4e4b"
      },
      "source": [
        "print(x_train.shape,\n",
        "y_train.shape\n",
        ",x_test.shape\n",
        ",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "P0TJjy7edCcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804f49cc-9e0d-4c74-e7c4-2d54e00072a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "print(y_train.shape)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],28*28).transpose()\n",
        "y_train = y_train.transpose()\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]).transpose()\n",
        "y_test = y_test.transpose()\n",
        "\n",
        "x_train = x_train.astype('float')\n",
        "x_train /= 255\n",
        "x_test = x_test.astype('float')\n",
        "x_test /= 255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJW81f6EeUPe"
      },
      "outputs": [],
      "source": [
        "classifier = Network()\n",
        "\n",
        "classifier.add(FCLayer(28*28, 200))\n",
        "classifier.add(ActivationLayer(activation = tanh, activation_derivative = tanh_derivative))\n",
        "classifier.add(FCLayer(200, 100))\n",
        "classifier.add(ActivationLayer(activation = tanh, activation_derivative = tanh_derivative))\n",
        "classifier.add(FCLayer(100, 50))\n",
        "classifier.add(ActivationLayer(activation = tanh, activation_derivative = tanh_derivative))\n",
        "classifier.add(FCLayer(50, 10))\n",
        "classifier.add(ActivationLayer(activation = sigmoid, activation_derivative = sigmoid_derivative))\n",
        "\n",
        "classifier.use(mse, mse_derivative)\n",
        "classifier.fit(x_train[:][:1000],y_train[:][:1000],epochs = 100, learning_rate = 25)\n",
        "result = classifier.predict(x_train[:][:1000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = classifier.predict(x_test)\n",
        "print(f\"test set accuracy : {accuracy(y_test,test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNr0TtDxHa7D",
        "outputId": "0a62530e-6d95-45a2-ca26-c0f0b144ec04"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set accuracy : 98.05199999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def digit(array):\n",
        "  return np.argmax(array)"
      ],
      "metadata": {
        "id": "2377aB-MJOT3"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_image_and_pred(img_number):\n",
        "  z = x_train[:,img_number:img_number+1]\n",
        "  image = z.reshape(28,28)\n",
        "  result = classifier.predict(z)\n",
        "  fig = plt.figure\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.show\n",
        "  print(f\"prediction = {digit(result)}\")"
      ],
      "metadata": {
        "id": "iBVtHRGZcPFq"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "choice = randrange(0,10000)\n",
        "print(f\"digit number {choice+1} of the test set\",end = \"\\n\\n\")\n",
        "show_image_and_pred(choice)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "ISdVVv_1IaIW",
        "outputId": "ff142e42-8ba4-42bf-c5fe-50d4a7f694ee"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digit number 8511 of the test set\n",
            "\n",
            "prediction = 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4J1tSBiO3gL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyOfyQIYW7toe8uB1c9wGqzd",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
