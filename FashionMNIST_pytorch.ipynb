{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmerDiaaeldin/Machine-Learning/blob/main/FashionMNIST_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-2u11JtIj4Gw"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "bHJcI4oZqx-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = \"./fashionmnist/\"\n",
        "if not os.path.exists(dir_path):\n",
        "  os.makedirs(dir_path)"
      ],
      "metadata": {
        "id": "VRQKdPaBj5Yn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root = dir_path,\n",
        "    train = True,\n",
        "    download=True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform=None,\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = dir_path,\n",
        "    train = False,\n",
        "    download=True,\n",
        "    transform = ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "MCDR_J21lDIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]"
      ],
      "metadata": {
        "id": "G2qXheUJmN-E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes"
      ],
      "metadata": {
        "id": "EcSk9ZH2mQ1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap = plt.get_cmap(\"gray\"))"
      ],
      "metadata": {
        "id": "i-664eLmndQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "id": "Y9P7MBv6olXR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_time(start,end):\n",
        "  total_time = end - start\n",
        "  print(f\"Train time {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "WdUfysFnCuiX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "class model(nn.Module):\n",
        "  def __init__(self, input_shape, output_shape):\n",
        "    super().__init__()\n",
        "    self.train_loss_history = []\n",
        "    self.test_loss_history = []\n",
        "    self.train_accuracy_history = []\n",
        "    self.test_accuracy_history = []\n",
        "    self.in_channels = input_shape[0]\n",
        "    self.height = input_shape[1]\n",
        "    self.width = input_shape[2]\n",
        "    self.output_shape = output_shape\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = self.in_channels, \n",
        "                  out_channels = 32,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1,\n",
        "                  ),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 32, \n",
        "                  out_channels = 64,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1,\n",
        "                  ),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(in_features=64*7*7, out_features=10),\n",
        "    )\n",
        "\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "    self.optimizer = torch.optim.SGD(self.parameters(), lr = 0.1)\n",
        "\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def accuracy_fn(self, y_pred, y_true):\n",
        "    return torch.eq(y_pred.argmax(dim=1), y_true).sum().item()*100/len(y_true)\n",
        "\n",
        "  def fit(self, epochs, train_data_loader: torch.utils.data.DataLoader, test_data_loader: torch.utils.data.DataLoader):\n",
        "    \n",
        "    start_time = timer()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      \n",
        "      train_loss = 0\n",
        "      train_acc = 0\n",
        "      \n",
        "      for batch, (X,y) in enumerate(train_data_loader):\n",
        "\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        self.train()\n",
        "        y_pred = self(X)\n",
        "\n",
        "        loss = self.loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += self.accuracy_fn(y_pred,y)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "      train_loss /= len(train_data_loader)\n",
        "      train_acc /= len(train_data_loader)\n",
        "\n",
        "      test_loss, test_acc = 0, 0 \n",
        "      self.eval()\n",
        "      with torch.inference_mode():\n",
        "        for (X, y) in test_data_loader:\n",
        "          X,y = X.to(device), y.to(device)\n",
        "          test_pred = self(X)\n",
        "          test_loss += self.loss_fn(test_pred, y)\n",
        "          test_acc += self.accuracy_fn(test_pred,y)\n",
        "        test_loss /= len(test_data_loader)\n",
        "        test_acc /= len(test_data_loader)\n",
        "      self.train_loss_history.append(train_loss.to('cpu').item())\n",
        "      self.test_loss_history.append(test_loss.to('cpu').item())\n",
        "      self.train_accuracy_history.append(train_acc)\n",
        "      self.test_accuracy_history.append(test_acc)\n",
        "      end_time = timer()\n",
        "      print(f\"\\nTrain loss: {train_loss:.5f}, Train acc: {train_acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "      print_time(start_time,end_time)\n",
        "    return [self.train_loss_history, self.test_loss_history, self.train_accuracy_history, self.test_accuracy_history]"
      ],
      "metadata": {
        "id": "YnXjV6_bqPKI"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0 = model([1,28,28],10).to(device)"
      ],
      "metadata": {
        "id": "TCcxAS4mDdKg"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[train_loss, test_loss, train_acc, test_acc] = model0.fit(10,train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "id": "Nyy66OvDDm8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "choice = randrange(len(test_data))\n",
        "with torch.inference_mode():\n",
        "  image = test_data[choice][0].unsqueeze(dim=0)\n",
        "  label = test_data[choice][1]\n",
        "\n",
        "  plt.imshow(image.squeeze(), cmap = plt.get_cmap('gray'))\n",
        "\n",
        "  image = image.to(device)\n",
        "  logits = model0(image)\n",
        "  pred = torch.argmax(logits).item()\n",
        "  print(f\"pred: {pred},label: {label}\")\n",
        "  print(f\"class: {train_data.classes[pred]}\")"
      ],
      "metadata": {
        "id": "QMYZkOfnr0qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(test_loss, label='test')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"loss vs iterations\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HgPSjATQsOHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc, label = 'train')\n",
        "plt.plot(test_acc, label='test')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"accuracy vs iterations\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4kmZ7o3F4wgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tOdQUjQ68taI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUknF0nC4ijXcymyohvWgD",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}